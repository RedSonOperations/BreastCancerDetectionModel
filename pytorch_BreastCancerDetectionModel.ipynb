{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7quJA6ONalqm",
        "outputId": "7f64db02-61ce-449c-eae9-f36fd9768164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121, running on cpu\n"
          ]
        }
      ],
      "source": [
        "#!pip install torchmetrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchmetrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics import Accuracy, ConfusionMatrix, F1Score, Precision\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"{torch.__version__}, running on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n",
        "                  columns= np.append(cancer['feature_names'], ['target']))\n",
        "df\n",
        "\n",
        "df.corr()['target']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZzMcmehbPmU",
        "outputId": "55de713b-a645-42bd-a237-75b8230e8662"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius               -0.730029\n",
              "mean texture              -0.415185\n",
              "mean perimeter            -0.742636\n",
              "mean area                 -0.708984\n",
              "mean smoothness           -0.358560\n",
              "mean compactness          -0.596534\n",
              "mean concavity            -0.696360\n",
              "mean concave points       -0.776614\n",
              "mean symmetry             -0.330499\n",
              "mean fractal dimension     0.012838\n",
              "radius error              -0.567134\n",
              "texture error              0.008303\n",
              "perimeter error           -0.556141\n",
              "area error                -0.548236\n",
              "smoothness error           0.067016\n",
              "compactness error         -0.292999\n",
              "concavity error           -0.253730\n",
              "concave points error      -0.408042\n",
              "symmetry error             0.006522\n",
              "fractal dimension error   -0.077972\n",
              "worst radius              -0.776454\n",
              "worst texture             -0.456903\n",
              "worst perimeter           -0.782914\n",
              "worst area                -0.733825\n",
              "worst smoothness          -0.421465\n",
              "worst compactness         -0.590998\n",
              "worst concavity           -0.659610\n",
              "worst concave points      -0.793566\n",
              "worst symmetry            -0.416294\n",
              "worst fractal dimension   -0.323872\n",
              "target                     1.000000\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select features\n",
        "#indices_to_del=[1, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 25, 28, 29]\n",
        "#indices_to_del=[1, 4, 8, 9, 11, 14, 15, 16, 17, 18, 19, 21, 24, 28, 29]\n",
        "\n",
        "X=cancer.data\n",
        "\n",
        "y=cancer.target\n",
        "#X = np.delete(X, indices_to_del, axis=1)  # Remove columns with specified indices\n",
        "X=torch.from_numpy(X).type(torch.float32)\n",
        "y=torch.from_numpy(y).type(torch.float32)\n",
        "X.shape, y.shape\n",
        "INPUTS_ALL = X.shape[1]\n",
        "print(INPUTS_ALL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOQCCWhLnnIa",
        "outputId": "92ccef04-40d5-4c41-d007-01b99531f68c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "xeqXIHI9_dJy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #ONLY RUN THESE CELLS FOR NON PYTORCH TRAINING OF MODEL AND COMMENT OUT numpy->torch above\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# # Create a Logistic Regression model\n",
        "# model = LogisticRegression()\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "snjJ3ZIu_gd-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Predict on the test set\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# # Other evaluation metrics\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# # Confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# print(\"Confusion Matrix:\")\n",
        "# print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "xOnjfHTA_jzM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "X_train.to(device)\n",
        "X_test.to(device)\n",
        "y_train.to(device)\n",
        "y_test.to(device)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KEKdXA_oDJ2",
        "outputId": "a7a7316e-17f0-4cc2-f802-38a7d7e7d256"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([381, 30]),\n",
              " torch.Size([188, 30]),\n",
              " torch.Size([381]),\n",
              " torch.Size([188]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define our model\n",
        "torch.manual_seed(42)\n",
        "class CancerPredictionModel(nn.Module):\n",
        "  def __init__(self, in_features, hidden_neurons):\n",
        "    super().__init__()\n",
        "    self.layer1=nn.Linear(in_features=in_features, out_features=hidden_neurons)\n",
        "    self.layer2=nn.Linear(in_features=hidden_neurons, out_features=hidden_neurons)\n",
        "    self.layer3=nn.Linear(in_features=hidden_neurons, out_features=1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "  def forward(self, x: torch.Tensor)->torch.Tensor:\n",
        "    return self.sigmoid(self.layer3(self.sigmoid(self.layer2(self.sigmoid(self.layer1(x))))))\n",
        "\n",
        "breast_cancer_model = CancerPredictionModel(in_features=INPUTS_ALL, hidden_neurons=64).to(device)"
      ],
      "metadata": {
        "id": "Or132NWhom41"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define loss function, accuracy function, and optimizer\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params=breast_cancer_model.parameters(), lr=0.005)\n",
        "\n",
        "def accuracy(y_test, y_preds):\n",
        "  correct=torch.eq(y_test, y_preds).sum().item()\n",
        "  return (correct/len(y_preds)) * 100\n"
      ],
      "metadata": {
        "id": "e67vrMccsePp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train our model\n",
        "torch.manual_seed(42)\n",
        "#epochs=13982 for best test accuracy, epochs=19563 for lowest test loss, epochs=15576 for best training accuracy, epochs=19693 for lowest training loss on random seed 42\n",
        "epochs=13982\n",
        "epochs_arr = []\n",
        "train_loss_arr = []\n",
        "test_loss_arr = []\n",
        "train_acc_arr = []\n",
        "test_acc_arr = []\n",
        "patience = 100  # Number of epochs to wait for improvement\n",
        "best_test_loss = np.inf  # Initializing with a large value\n",
        "counter = 0  # Counter to track epochs without improvement\n",
        "best_model_state = None  # To store the best model's state\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  breast_cancer_model.train()\n",
        "  y_preds = (breast_cancer_model(X_train)).squeeze()\n",
        "\n",
        "  loss=loss_func(y_preds, y_train)\n",
        "  acc=torchmetrics.Accuracy(task='binary')\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  breast_cancer_model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_preds = (breast_cancer_model(X_test)).squeeze()\n",
        "    test_loss = loss_func(test_preds, y_test)\n",
        "    test_acc = torchmetrics.Accuracy(task='binary')\n",
        "  epochs_arr.append(epoch)\n",
        "  train_loss_arr.append(loss.detach().numpy())\n",
        "  test_loss_arr.append(test_loss.detach().numpy())\n",
        "  train_acc_arr.append(acc(y_preds, y_train).detach().numpy())\n",
        "  test_acc_arr.append(test_acc(test_preds, y_test).detach().numpy())\n",
        "  if(epoch%100==0):\n",
        "     print(f\"Epoch {epoch} -- Training Accuracy: {acc(y_preds, y_train)}, Testing Accuracy: {test_acc(test_preds, y_test)}, Training Loss: {loss}, Testing Loss: {test_loss}\")\n",
        "  # Early stopping check\n",
        "  if test_acc < best_test_loss:\n",
        "      best_test_loss = test_acc\n",
        "      counter = 0\n",
        "      # Update the best model state\n",
        "      best_model_state = breast_cancer_model.state_dict()\n",
        "  else:\n",
        "      counter += 1\n",
        "      if counter >= patience:\n",
        "         print(f\"Early stopping at epoch {epoch}.\")\n",
        "         break\n",
        "\n",
        "# If early stopping occurred, load the best model state\n",
        "if best_model_state is not None:\n",
        "    breast_cancer_model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGp6ucq9rbNB",
        "outputId": "39bb884f-2aee-4650-ee63-8c279b125cf1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 -- Training Accuracy: 0.46194225549697876, Testing Accuracy: 0.4680851101875305, Training Loss: 0.6947268843650818, Testing Loss: 0.693275511264801\n",
            "Epoch 100 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6563295125961304, Testing Loss: 0.6445732712745667\n",
            "Epoch 200 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6533501744270325, Testing Loss: 0.6402064561843872\n",
            "Epoch 300 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6505269408226013, Testing Loss: 0.6369409561157227\n",
            "Epoch 400 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6473849415779114, Testing Loss: 0.6334066987037659\n",
            "Epoch 500 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6440069079399109, Testing Loss: 0.6295977234840393\n",
            "Epoch 600 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6386760473251343, Testing Loss: 0.6234966516494751\n",
            "Epoch 700 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.634181559085846, Testing Loss: 0.6182876825332642\n",
            "Epoch 800 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6293451189994812, Testing Loss: 0.6129333972930908\n",
            "Epoch 900 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6242321729660034, Testing Loss: 0.6071990132331848\n",
            "Epoch 1000 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6186864376068115, Testing Loss: 0.6009697914123535\n",
            "Epoch 1100 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.6127544641494751, Testing Loss: 0.5942515730857849\n",
            "Epoch 1200 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.604598879814148, Testing Loss: 0.5852904915809631\n",
            "Epoch 1300 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.5970019102096558, Testing Loss: 0.5768060684204102\n",
            "Epoch 1400 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.5881210565567017, Testing Loss: 0.5674334764480591\n",
            "Epoch 1500 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.5790888071060181, Testing Loss: 0.557206928730011\n",
            "Epoch 1600 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.5694801807403564, Testing Loss: 0.5464145541191101\n",
            "Epoch 1700 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.559296190738678, Testing Loss: 0.5349006056785583\n",
            "Epoch 1800 -- Training Accuracy: 0.6194225549697876, Testing Accuracy: 0.6436170339584351, Training Loss: 0.5486200451850891, Testing Loss: 0.5227527618408203\n",
            "Epoch 1900 -- Training Accuracy: 0.7979002594947815, Testing Accuracy: 0.8510638475418091, Training Loss: 0.5375235676765442, Testing Loss: 0.5100454092025757\n",
            "Epoch 2000 -- Training Accuracy: 0.8503937125205994, Testing Accuracy: 0.914893627166748, Training Loss: 0.5257083773612976, Testing Loss: 0.49684539437294006\n",
            "Epoch 2100 -- Training Accuracy: 0.8661417365074158, Testing Accuracy: 0.914893627166748, Training Loss: 0.5135547518730164, Testing Loss: 0.48321643471717834\n",
            "Epoch 2200 -- Training Accuracy: 0.8635170459747314, Testing Accuracy: 0.9255319237709045, Training Loss: 0.5009905695915222, Testing Loss: 0.469538152217865\n",
            "Epoch 2300 -- Training Accuracy: 0.8661417365074158, Testing Accuracy: 0.9308510422706604, Training Loss: 0.48823675513267517, Testing Loss: 0.45503294467926025\n",
            "Epoch 2400 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.9468085169792175, Training Loss: 0.47564035654067993, Testing Loss: 0.4404449462890625\n",
            "Epoch 2500 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9468085169792175, Training Loss: 0.46314525604248047, Testing Loss: 0.42603036761283875\n",
            "Epoch 2600 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9468085169792175, Training Loss: 0.45080891251564026, Testing Loss: 0.4117054343223572\n",
            "Epoch 2700 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9521276354789734, Training Loss: 0.43857601284980774, Testing Loss: 0.39753109216690063\n",
            "Epoch 2800 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.9468085169792175, Training Loss: 0.42701059579849243, Testing Loss: 0.38399171829223633\n",
            "Epoch 2900 -- Training Accuracy: 0.8923884630203247, Testing Accuracy: 0.9468085169792175, Training Loss: 0.41544950008392334, Testing Loss: 0.36984333395957947\n",
            "Epoch 3000 -- Training Accuracy: 0.8897637724876404, Testing Accuracy: 0.9468085169792175, Training Loss: 0.4044952690601349, Testing Loss: 0.35637226700782776\n",
            "Epoch 3100 -- Training Accuracy: 0.8897637724876404, Testing Accuracy: 0.9468085169792175, Training Loss: 0.3942285180091858, Testing Loss: 0.34372052550315857\n",
            "Epoch 3200 -- Training Accuracy: 0.8923884630203247, Testing Accuracy: 0.9521276354789734, Training Loss: 0.38509294390678406, Testing Loss: 0.33389419317245483\n",
            "Epoch 3300 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.957446813583374, Training Loss: 0.37550777196884155, Testing Loss: 0.32178226113319397\n",
            "Epoch 3400 -- Training Accuracy: 0.8976377844810486, Testing Accuracy: 0.9468085169792175, Training Loss: 0.3652256727218628, Testing Loss: 0.3065776526927948\n",
            "Epoch 3500 -- Training Accuracy: 0.8976377844810486, Testing Accuracy: 0.9468085169792175, Training Loss: 0.35472002625465393, Testing Loss: 0.2995971441268921\n",
            "Epoch 3600 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.9521276354789734, Training Loss: 0.3558282256126404, Testing Loss: 0.2926952838897705\n",
            "Epoch 3700 -- Training Accuracy: 0.8923884630203247, Testing Accuracy: 0.9308510422706604, Training Loss: 0.3567655384540558, Testing Loss: 0.3047511875629425\n",
            "Epoch 3800 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.957446813583374, Training Loss: 0.33429524302482605, Testing Loss: 0.2679623067378998\n",
            "Epoch 3900 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9521276354789734, Training Loss: 0.3329911231994629, Testing Loss: 0.27171778678894043\n",
            "Epoch 4000 -- Training Accuracy: 0.8923884630203247, Testing Accuracy: 0.9468085169792175, Training Loss: 0.3315832018852234, Testing Loss: 0.26664456725120544\n",
            "Epoch 4100 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.957446813583374, Training Loss: 0.3201679289340973, Testing Loss: 0.24683944880962372\n",
            "Epoch 4200 -- Training Accuracy: 0.8976377844810486, Testing Accuracy: 0.957446813583374, Training Loss: 0.31588783860206604, Testing Loss: 0.24697476625442505\n",
            "Epoch 4300 -- Training Accuracy: 0.887139081954956, Testing Accuracy: 0.9521276354789734, Training Loss: 0.34643155336380005, Testing Loss: 0.2616671323776245\n",
            "Epoch 4400 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9468085169792175, Training Loss: 0.3050065338611603, Testing Loss: 0.2418932467699051\n",
            "Epoch 4500 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.936170220375061, Training Loss: 0.3102535605430603, Testing Loss: 0.25331592559814453\n",
            "Epoch 4600 -- Training Accuracy: 0.8556430339813232, Testing Accuracy: 0.936170220375061, Training Loss: 0.3650815188884735, Testing Loss: 0.2609013020992279\n",
            "Epoch 4700 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2942851185798645, Testing Loss: 0.22257526218891144\n",
            "Epoch 4800 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2965094745159149, Testing Loss: 0.22768071293830872\n",
            "Epoch 4900 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2919869124889374, Testing Loss: 0.21451832354068756\n",
            "Epoch 5000 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.9521276354789734, Training Loss: 0.29218411445617676, Testing Loss: 0.2087676227092743\n",
            "Epoch 5100 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9627659320831299, Training Loss: 0.27127406001091003, Testing Loss: 0.1898704618215561\n",
            "Epoch 5200 -- Training Accuracy: 0.9055117964744568, Testing Accuracy: 0.9521276354789734, Training Loss: 0.29637593030929565, Testing Loss: 0.1966894418001175\n",
            "Epoch 5300 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9521276354789734, Training Loss: 0.28372591733932495, Testing Loss: 0.19909566640853882\n",
            "Epoch 5400 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.957446813583374, Training Loss: 0.2641446590423584, Testing Loss: 0.20221608877182007\n",
            "Epoch 5500 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2687077522277832, Testing Loss: 0.19005097448825836\n",
            "Epoch 5600 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9414893388748169, Training Loss: 0.2774810492992401, Testing Loss: 0.21763698756694794\n",
            "Epoch 5700 -- Training Accuracy: 0.8976377844810486, Testing Accuracy: 0.957446813583374, Training Loss: 0.27361783385276794, Testing Loss: 0.1879643201828003\n",
            "Epoch 5800 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.957446813583374, Training Loss: 0.25859200954437256, Testing Loss: 0.1758890151977539\n",
            "Epoch 5900 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2627159059047699, Testing Loss: 0.18131901323795319\n",
            "Epoch 6000 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.957446813583374, Training Loss: 0.24884623289108276, Testing Loss: 0.18771255016326904\n",
            "Epoch 6100 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9468085169792175, Training Loss: 0.26395344734191895, Testing Loss: 0.17115327715873718\n",
            "Epoch 6200 -- Training Accuracy: 0.9055117964744568, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2698507606983185, Testing Loss: 0.18052202463150024\n",
            "Epoch 6300 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.936170220375061, Training Loss: 0.25477278232574463, Testing Loss: 0.1944354921579361\n",
            "Epoch 6400 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.957446813583374, Training Loss: 0.2427085041999817, Testing Loss: 0.17539744079113007\n",
            "Epoch 6500 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9414893388748169, Training Loss: 0.24488067626953125, Testing Loss: 0.17678923904895782\n",
            "Epoch 6600 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2532252371311188, Testing Loss: 0.17008820176124573\n",
            "Epoch 6700 -- Training Accuracy: 0.9055117964744568, Testing Accuracy: 0.9468085169792175, Training Loss: 0.24391359090805054, Testing Loss: 0.16885142028331757\n",
            "Epoch 6800 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2517283260822296, Testing Loss: 0.17699487507343292\n",
            "Epoch 6900 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2576204240322113, Testing Loss: 0.1845102459192276\n",
            "Epoch 7000 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2651653587818146, Testing Loss: 0.1876044124364853\n",
            "Epoch 7100 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.957446813583374, Training Loss: 0.23793677985668182, Testing Loss: 0.17506727576255798\n",
            "Epoch 7200 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2854039967060089, Testing Loss: 0.18312525749206543\n",
            "Epoch 7300 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9627659320831299, Training Loss: 0.2356092780828476, Testing Loss: 0.15011152625083923\n",
            "Epoch 7400 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2366052269935608, Testing Loss: 0.1577838957309723\n",
            "Epoch 7500 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.957446813583374, Training Loss: 0.2334432452917099, Testing Loss: 0.1418578028678894\n",
            "Epoch 7600 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9627659320831299, Training Loss: 0.2294793576002121, Testing Loss: 0.14277547597885132\n",
            "Epoch 7700 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9627659320831299, Training Loss: 0.22943399846553802, Testing Loss: 0.14897987246513367\n",
            "Epoch 7800 -- Training Accuracy: 0.9002624750137329, Testing Accuracy: 0.9521276354789734, Training Loss: 0.23252838850021362, Testing Loss: 0.15475936233997345\n",
            "Epoch 7900 -- Training Accuracy: 0.9055117964744568, Testing Accuracy: 0.9627659320831299, Training Loss: 0.22908294200897217, Testing Loss: 0.14081482589244843\n",
            "Epoch 8000 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.9627659320831299, Training Loss: 0.22796660661697388, Testing Loss: 0.1506190001964569\n",
            "Epoch 8100 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9627659320831299, Training Loss: 0.218349426984787, Testing Loss: 0.14471034705638885\n",
            "Epoch 8200 -- Training Accuracy: 0.8950130939483643, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2347044050693512, Testing Loss: 0.16538017988204956\n",
            "Epoch 8300 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9627659320831299, Training Loss: 0.21639597415924072, Testing Loss: 0.13684502243995667\n",
            "Epoch 8400 -- Training Accuracy: 0.9238845109939575, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2263324111700058, Testing Loss: 0.17061571776866913\n",
            "Epoch 8500 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9468085169792175, Training Loss: 0.23093333840370178, Testing Loss: 0.1790577918291092\n",
            "Epoch 8600 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.22265318036079407, Testing Loss: 0.14421077072620392\n",
            "Epoch 8700 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9521276354789734, Training Loss: 0.21919022500514984, Testing Loss: 0.143038809299469\n",
            "Epoch 8800 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9627659320831299, Training Loss: 0.2215670645236969, Testing Loss: 0.14266115427017212\n",
            "Epoch 8900 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9414893388748169, Training Loss: 0.2180689573287964, Testing Loss: 0.15950998663902283\n",
            "Epoch 9000 -- Training Accuracy: 0.9028871655464172, Testing Accuracy: 0.9627659320831299, Training Loss: 0.22005882859230042, Testing Loss: 0.13728581368923187\n",
            "Epoch 9100 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.936170220375061, Training Loss: 0.2234070599079132, Testing Loss: 0.17542172968387604\n",
            "Epoch 9200 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9521276354789734, Training Loss: 0.22441862523555756, Testing Loss: 0.1530023068189621\n",
            "Epoch 9300 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9627659320831299, Training Loss: 0.21368582546710968, Testing Loss: 0.1334117352962494\n",
            "Epoch 9400 -- Training Accuracy: 0.9055117964744568, Testing Accuracy: 0.9468085169792175, Training Loss: 0.21387702226638794, Testing Loss: 0.14434480667114258\n",
            "Epoch 9500 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.957446813583374, Training Loss: 0.20788612961769104, Testing Loss: 0.13317535817623138\n",
            "Epoch 9600 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.21615825593471527, Testing Loss: 0.13840000331401825\n",
            "Epoch 9700 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20929603278636932, Testing Loss: 0.14143985509872437\n",
            "Epoch 9800 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.957446813583374, Training Loss: 0.20904918015003204, Testing Loss: 0.13701112568378448\n",
            "Epoch 9900 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20652006566524506, Testing Loss: 0.13742469251155853\n",
            "Epoch 10000 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20451682806015015, Testing Loss: 0.1315893828868866\n",
            "Epoch 10100 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2146727442741394, Testing Loss: 0.14245639741420746\n",
            "Epoch 10200 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20435212552547455, Testing Loss: 0.13390794396400452\n",
            "Epoch 10300 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.9468085169792175, Training Loss: 0.2076432853937149, Testing Loss: 0.14526531100273132\n",
            "Epoch 10400 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2057582437992096, Testing Loss: 0.1303585171699524\n",
            "Epoch 10500 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.957446813583374, Training Loss: 0.20026443898677826, Testing Loss: 0.12467250227928162\n",
            "Epoch 10600 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.957446813583374, Training Loss: 0.20170697569847107, Testing Loss: 0.12702873349189758\n",
            "Epoch 10700 -- Training Accuracy: 0.9081364870071411, Testing Accuracy: 0.936170220375061, Training Loss: 0.2177620679140091, Testing Loss: 0.1553725153207779\n",
            "Epoch 10800 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9414893388748169, Training Loss: 0.21019867062568665, Testing Loss: 0.14583057165145874\n",
            "Epoch 10900 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9468085169792175, Training Loss: 0.19656038284301758, Testing Loss: 0.13240844011306763\n",
            "Epoch 11000 -- Training Accuracy: 0.9291338324546814, Testing Accuracy: 0.9308510422706604, Training Loss: 0.20477446913719177, Testing Loss: 0.15457120537757874\n",
            "Epoch 11100 -- Training Accuracy: 0.8976377844810486, Testing Accuracy: 0.9414893388748169, Training Loss: 0.2207489162683487, Testing Loss: 0.14418268203735352\n",
            "Epoch 11200 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20182184875011444, Testing Loss: 0.13655728101730347\n",
            "Epoch 11300 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20559199154376984, Testing Loss: 0.1367635577917099\n",
            "Epoch 11400 -- Training Accuracy: 0.913385808467865, Testing Accuracy: 0.957446813583374, Training Loss: 0.196724534034729, Testing Loss: 0.12261170893907547\n",
            "Epoch 11500 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9521276354789734, Training Loss: 0.1973625272512436, Testing Loss: 0.1266636848449707\n",
            "Epoch 11600 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.9468085169792175, Training Loss: 0.20690828561782837, Testing Loss: 0.12644246220588684\n",
            "Epoch 11700 -- Training Accuracy: 0.9291338324546814, Testing Accuracy: 0.957446813583374, Training Loss: 0.20351678133010864, Testing Loss: 0.13642430305480957\n",
            "Epoch 11800 -- Training Accuracy: 0.9317585229873657, Testing Accuracy: 0.9414893388748169, Training Loss: 0.19875013828277588, Testing Loss: 0.1379849910736084\n",
            "Epoch 11900 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.957446813583374, Training Loss: 0.19972077012062073, Testing Loss: 0.13334523141384125\n",
            "Epoch 12000 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.957446813583374, Training Loss: 0.2001713365316391, Testing Loss: 0.1352686882019043\n",
            "Epoch 12100 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20503060519695282, Testing Loss: 0.1375851333141327\n",
            "Epoch 12200 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.957446813583374, Training Loss: 0.2014690786600113, Testing Loss: 0.1411251723766327\n",
            "Epoch 12300 -- Training Accuracy: 0.9291338324546814, Testing Accuracy: 0.9680851101875305, Training Loss: 0.19469131529331207, Testing Loss: 0.12679743766784668\n",
            "Epoch 12400 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.9627659320831299, Training Loss: 0.19084058701992035, Testing Loss: 0.1258508563041687\n",
            "Epoch 12500 -- Training Accuracy: 0.9291338324546814, Testing Accuracy: 0.957446813583374, Training Loss: 0.19545027613639832, Testing Loss: 0.1324445903301239\n",
            "Epoch 12600 -- Training Accuracy: 0.9317585229873657, Testing Accuracy: 0.9414893388748169, Training Loss: 0.20001012086868286, Testing Loss: 0.1441268026828766\n",
            "Epoch 12700 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2166273295879364, Testing Loss: 0.13802137970924377\n",
            "Epoch 12800 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.957446813583374, Training Loss: 0.195270374417305, Testing Loss: 0.12412973493337631\n",
            "Epoch 12900 -- Training Accuracy: 0.9186351895332336, Testing Accuracy: 0.9468085169792175, Training Loss: 0.21303686499595642, Testing Loss: 0.13662923872470856\n",
            "Epoch 13000 -- Training Accuracy: 0.9291338324546814, Testing Accuracy: 0.9521276354789734, Training Loss: 0.19802409410476685, Testing Loss: 0.13191917538642883\n",
            "Epoch 13100 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9202127456665039, Training Loss: 0.20934492349624634, Testing Loss: 0.1600784808397293\n",
            "Epoch 13200 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9468085169792175, Training Loss: 0.19388748705387115, Testing Loss: 0.1367151290178299\n",
            "Epoch 13300 -- Training Accuracy: 0.9107611775398254, Testing Accuracy: 0.9468085169792175, Training Loss: 0.20371899008750916, Testing Loss: 0.1334337741136551\n",
            "Epoch 13400 -- Training Accuracy: 0.9317585229873657, Testing Accuracy: 0.9521276354789734, Training Loss: 0.19527080655097961, Testing Loss: 0.13647355139255524\n",
            "Epoch 13500 -- Training Accuracy: 0.93438321352005, Testing Accuracy: 0.9734042286872864, Training Loss: 0.1971943974494934, Testing Loss: 0.13404683768749237\n",
            "Epoch 13600 -- Training Accuracy: 0.9212598204612732, Testing Accuracy: 0.9521276354789734, Training Loss: 0.2038593292236328, Testing Loss: 0.12449710816144943\n",
            "Epoch 13700 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.9468085169792175, Training Loss: 0.20091207325458527, Testing Loss: 0.13702073693275452\n",
            "Epoch 13800 -- Training Accuracy: 0.9160104990005493, Testing Accuracy: 0.9521276354789734, Training Loss: 0.20662403106689453, Testing Loss: 0.13138136267662048\n",
            "Epoch 13900 -- Training Accuracy: 0.9265092015266418, Testing Accuracy: 0.9521276354789734, Training Loss: 0.1861819326877594, Testing Loss: 0.128105029463768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_trainloss=np.argmin(train_loss_arr)\n",
        "epoch_min_trainloss=epochs_arr[min_trainloss]\n",
        "\n",
        "min_testloss=np.argmin(test_loss_arr)\n",
        "epoch_min_testloss=epochs_arr[min_testloss]\n",
        "\n",
        "max_trainacc=np.argmax(train_acc_arr)\n",
        "epoch_max_trainacc=epochs_arr[max_trainacc]\n",
        "\n",
        "max_testacc=np.argmax(test_acc_arr)\n",
        "epoch_max_testacc=epochs_arr[max_testacc]\n",
        "\n",
        "#choose a metric preference - optimal loss and accuracy params, epoch # @ these\n",
        "print(f\"Min training loss: {np.min(train_loss_arr)}, Epoch # {epoch_min_trainloss}\")\n",
        "print(f\"Min testing loss: {np.min(test_loss_arr)}, Epoch # {epoch_min_testloss}\")\n",
        "print(f\"Max training accuracy: {np.max(train_acc_arr)}, Epoch # {epoch_max_trainacc}\")\n",
        "print(f\"Max testing accuracy: {np.max(test_acc_arr)}, Epoch # {epoch_max_testacc}\")\n",
        "\n",
        "#uncomment if you wish to see training data confusion matrix\n",
        "# cf_train=torchmetrics.ConfusionMatrix(task='binary')\n",
        "# cf_train(y_preds, y_train)\n",
        "\n",
        "# cf_train.plot()\n",
        "# print(\"Training Data\")\n",
        "\n",
        "cf_test=torchmetrics.ConfusionMatrix(task='binary')\n",
        "cf_test(test_preds, y_test)\n",
        "\n",
        "cf_test.plot()\n",
        "print(\"Testing Data\")\n",
        "\n",
        "#conclusion: if we eliminate variables that do not have a high correlation with targets, we can use less neurons and layers thus reducing computational resources to gain nearly as accurate predictions as original data with more neurons and layers\n",
        "#with 20,000 epochs, we get the following results (increase epochs to decrease loss):\n",
        "#~94% training accuracy, ~97.5% testing accuracy, ~0.1 testing loss with low corr variables eliminated, 1 hidden layer, 64 neurons, lr=0.008\n",
        "#for consistent results and growth of accuracy/decrease of loss, use smaller learning rate with more epochs\n",
        "#~94.3% training accuracy, ~98.5% testing accuracy, ~0.095 testing loss with all original data, 2 hidden layers, 64 neurons, lr=0.005\n",
        "#~94.5% training accuracy, ~97.3% testing accuracy, ~0.090 testing loss with all original data, 1 hidden layer, 64 neurons, lr=0.01\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "kIL37we8GVV5",
        "outputId": "1acb8ca8-47ff-4bdd-ab5f-45d714f4a375"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min training loss: 0.1840297132730484, Epoch # 13461\n",
            "Min testing loss: 0.10968713462352753, Epoch # 13926\n",
            "Max training accuracy: 0.9370078444480896, Epoch # 13694\n",
            "Max testing accuracy: 0.9840425252914429, Epoch # 13981\n",
            "Testing Data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeHm_-XRLs9e"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}